{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027a3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from scipy.stats import rankdata\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.linear_model import RidgeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8386bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compute_capability': (8, 6), 'device_name': 'NVIDIA GeForce RTX 3050 Laptop GPU'}\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpu)\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed167af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(\"output_mslr_2000/export/best_model_by_loss/1684615624\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94f2df",
   "metadata": {},
   "source": [
    "## Load test data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14de25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('datasets/MSLR-WEB10K/test_mslr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06c25a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_label</th>\n",
       "      <th>qid</th>\n",
       "      <th>covered_query_term_number_body</th>\n",
       "      <th>covered_query_term_number_anchor</th>\n",
       "      <th>covered_query_term_number_title</th>\n",
       "      <th>covered_query_term_number_url</th>\n",
       "      <th>covered_query_term_number_whole_document</th>\n",
       "      <th>covered_query_term_ratio_body</th>\n",
       "      <th>covered_query_term_ratio_anchor</th>\n",
       "      <th>covered_query_term_ratio_title</th>\n",
       "      <th>...</th>\n",
       "      <th>length_url</th>\n",
       "      <th>inlink_number</th>\n",
       "      <th>outlink_number</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>siterank</th>\n",
       "      <th>qualityscore</th>\n",
       "      <th>qualityscore2</th>\n",
       "      <th>query_url_click_count</th>\n",
       "      <th>url_click_count</th>\n",
       "      <th>url_dwell_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>4.798976e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.382544</td>\n",
       "      <td>0.110236</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>4.463047e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.196231</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.017258</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032279</td>\n",
       "      <td>3.924362e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.934218</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884320</td>\n",
       "      <td>0.238041</td>\n",
       "      <td>0.059055</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance_label  qid  covered_query_term_number_body   \n",
       "0              2.0   13                        0.026667  \\\n",
       "1              1.0   13                        0.026667   \n",
       "2              3.0   13                        0.026667   \n",
       "3              1.0   13                        0.026667   \n",
       "4              0.0   13                        0.013333   \n",
       "\n",
       "   covered_query_term_number_anchor  covered_query_term_number_title   \n",
       "0                               0.0                         0.133333  \\\n",
       "1                               0.0                         0.000000   \n",
       "2                               0.0                         0.066667   \n",
       "3                               0.0                         0.133333   \n",
       "4                               0.0                         0.000000   \n",
       "\n",
       "   covered_query_term_number_url  covered_query_term_number_whole_document   \n",
       "0                       0.066667                                  0.026667  \\\n",
       "1                       0.000000                                  0.026667   \n",
       "2                       0.000000                                  0.026667   \n",
       "3                       0.066667                                  0.026667   \n",
       "4                       0.000000                                  0.013333   \n",
       "\n",
       "   covered_query_term_ratio_body  covered_query_term_ratio_anchor   \n",
       "0                            1.0                              0.0  \\\n",
       "1                            1.0                              0.0   \n",
       "2                            1.0                              0.0   \n",
       "3                            1.0                              0.0   \n",
       "4                            0.5                              0.0   \n",
       "\n",
       "   covered_query_term_ratio_title  ...  length_url  inlink_number   \n",
       "0                             1.0  ...    0.022595   4.798976e-10  \\\n",
       "1                             0.0  ...    0.010975   4.463047e-08   \n",
       "2                             0.5  ...    0.012266   0.000000e+00   \n",
       "3                             1.0  ...    0.032279   3.924362e-05   \n",
       "4                             0.0  ...    0.015494   0.000000e+00   \n",
       "\n",
       "   outlink_number  pagerank  siterank  qualityscore  qualityscore2   \n",
       "0             0.0  0.004059  0.382544      0.110236       0.027559  \\\n",
       "1             0.0  0.002335  0.196231      0.255906       0.622047   \n",
       "2             0.0  0.002335  0.017258      0.440945       0.555118   \n",
       "3             0.0  0.008545  0.934218      0.003937       0.055118   \n",
       "4             0.0  0.884320  0.238041      0.059055       0.047244   \n",
       "\n",
       "   query_url_click_count  url_click_count  url_dwell_time  \n",
       "0                    0.0              0.0             0.0  \n",
       "1                    0.0              0.0             0.0  \n",
       "2                    0.0              0.0             0.0  \n",
       "3                    0.0              0.0             0.0  \n",
       "4                    0.0              0.0             0.0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c5139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff19c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_all(examples):\n",
    "    \n",
    "    list_examples = []\n",
    "    for idx, row in examples.iterrows():     \n",
    "\n",
    "        example_dict = {\n",
    "                       f'{feat_name}':_float_feature(feat_val) for \n",
    "                        feat_name, feat_val in zip(df_test.columns.tolist()[2:], row.iloc[2:].tolist())\n",
    "                    }    \n",
    "        \n",
    "        example_dict['relevance_label'] = _int64_feature(int(row['relevance_label']))\n",
    "\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=example_dict))\n",
    "        list_examples.append(example_proto.SerializeToString())\n",
    "    return list_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d57bf9",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666e928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explanations:\n",
    "    def __init__(self, data, sample_size=20, visible_features=20, name_features = []):\n",
    "        self.data = data \n",
    "        self.sample_size = sample_size \n",
    "        self.kernel_width = np.sqrt(data.shape[1]) * .75\n",
    "        self.visible_features = visible_features\n",
    "        self.name_features = name_features\n",
    "        \n",
    "    def subscores_GAM(self, instances, idx):\n",
    "        acum_subscores = []\n",
    "        tensors = tf.convert_to_tensor(instances)\n",
    "        for fea in self.name_features:\n",
    "            tf_predictor = loaded_model.signatures[fea + '_subscore']\n",
    "            subscores = tf_predictor(tensors)\n",
    "            acum_subscores.append(subscores['outputs'][idx])\n",
    "        return tf.stack(acum_subscores)\n",
    "        \n",
    "    def predict_GAM(self, instances): \n",
    "        tf_example_predictor = loaded_model.signatures['predict']\n",
    "        scores = tf_example_predictor(tf.convert_to_tensor(instances))['output']\n",
    "        return scores\n",
    "\n",
    "    def kernel(self, d):\n",
    "    #similarity or weight based on the Gaussian kernel function\n",
    "        return np.sqrt(np.exp(-(d ** 2) / self.kernel_width ** 2))\n",
    "    \n",
    "    def empirical_sampling(self, instance_explained):\n",
    "        generated_docs = []\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = instance_explained.shape[0]\n",
    "            total_feature_selected = np.random.randint(0, num_features - 2) \n",
    "            selected_features = np.random.randint(2, num_features, total_feature_selected)\n",
    "\n",
    "            for sel_feat in selected_features:\n",
    "                instance_explained[sel_feat] = np.random.choice(self.data.iloc[:, sel_feat], 1)[0]\n",
    "\n",
    "            generated_docs.append(instance_explained)\n",
    "        return generated_docs\n",
    "    \n",
    "    def lime_inverse_zscore(self, instance_explained):\n",
    "        generated_docs = []\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = instance_explained.shape[0] \n",
    "            total_feature_selected = np.random.randint(0, num_features - 2)\n",
    "            selected_features = np.random.randint(2, num_features, total_feature_selected)\n",
    "\n",
    "            for sel_feat in selected_features:\n",
    "                mu = np.mean(self.data.iloc[:, sel_feat].values)\n",
    "                sigma = np.std(self.data.iloc[:, sel_feat].values)\n",
    "                z = np.random.normal(0, 1)\n",
    "                instance_explained[sel_feat] = z * sigma + mu\n",
    "\n",
    "            generated_docs.append(instance_explained)\n",
    "        return generated_docs\n",
    "    \n",
    "    def gaussian_sampling(self, instance_explained):\n",
    "        generated_docs = []\n",
    "        \n",
    "        unique_vals = {}\n",
    "        exclude_features = []\n",
    "\n",
    "        #PROBLEM: it never excludes any feature\n",
    "        for i in range(2, self.data.shape[1]):\n",
    "            dist = np.abs(self.data.iloc[:, i] - instance_explained[i])\n",
    "            unique_val = dist[ dist < np.std(self.data.iloc[:, i])].unique()\n",
    "            \n",
    "            if len(unique_val) > 0: \n",
    "                unique_vals[i] = unique_val\n",
    "            else: \n",
    "                exclude_features.append(i)\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = self.data.shape[1] \n",
    "            total_feature_selected = np.random.randint(0, num_features - 2 - len(exclude_features))\n",
    "            available_features = np.setxor1d(np.arange(2, num_features), exclude_features).astype(int)\n",
    "            selected_features = np.random.choice(available_features, total_feature_selected)\n",
    "            for c_feat in selected_features:\n",
    "                instance_explained[c_feat] = np.random.choice(unique_vals[c_feat], 1)[0]\n",
    "            generated_docs.append(instance_explained)\n",
    "        return generated_docs\n",
    "        \n",
    "    def get_explanations(self, qid_data, doc_idx, sampling): \n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        docs = serialize_all(qid_data) #list of tensor examples\n",
    "\n",
    "        original_scores = self.predict_GAM(docs) #prediction of docs given query\n",
    "        GAM_explanations = self.subscores_GAM(docs, doc_idx) #explanations ranking doc_idx\n",
    "        base_rank = rankdata([-1 * i for i in original_scores]).astype(int) - 1\n",
    "\n",
    "        instance_explained = copy.copy(qid_data.iloc[doc_idx])\n",
    "        \n",
    "        #returns list of new documents samples\n",
    "        if sampling == 'empirical':\n",
    "            generated_docs = self.empirical_sampling(instance_explained)\n",
    "        elif sampling == 'gaussian':\n",
    "            generated_docs = self.gaussian_sampling(instance_explained)\n",
    "        elif sampling == 'lime':\n",
    "            generated_docs = self.lime_inverse_zscore(instance_explained)\n",
    "        \n",
    "        generated_predictions = []\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            temp_docs = copy.copy(docs) #copy tensors\n",
    "            temp_docs[doc_idx] = serialize_all(generated_docs[t].to_frame().T)[0] #the selected instance is replaced\n",
    "            genere_pred = self.predict_GAM(temp_docs)\n",
    "            generated_predictions.append(genere_pred) #return tensor predict\n",
    "        \n",
    "        ranked_all = []\n",
    "        \n",
    "        for gen_pred in generated_predictions:\n",
    "            ranked_all.append(rankdata([-1 * i for i in gen_pred]).astype(int) - 1)\n",
    "        ranked_all = np.array(ranked_all)\n",
    "        \n",
    "        labels = []\n",
    "\n",
    "        for ranked in ranked_all: \n",
    "            if ranked[doc_idx] <= base_rank[doc_idx]: \n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "                \n",
    "        gen_docs = []\n",
    "        \n",
    "        for i in range(0, self.sample_size):\n",
    "            gen_docs.append(generated_docs[i].values[2:]) #all features of generated_docs\n",
    "        gen_docs = np.array(gen_docs).astype(np.float32)\n",
    "        \n",
    "        i_explained = instance_explained.values[2:].astype(np.float32)\n",
    "        distances = np.linalg.norm(gen_docs - i_explained, axis=1) #euclidean distance\n",
    "        k_weights = self.kernel(distances).astype(np.float32)\n",
    "        \n",
    "        clf = RidgeClassifier(alpha = 0.5).fit(gen_docs, labels, sample_weight=k_weights)\n",
    "        end = time.time()\n",
    "        \n",
    "        print('Time took for explanations: {} '.format(end - start))\n",
    "        \n",
    "        return GAM_explanations, tf.transpose(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1608f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_metrics(GAM_explanations, LIME_explanations):\n",
    "    \n",
    "    #RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(GAM_explanations, LIME_explanations))\n",
    "    \n",
    "    #MAE\n",
    "    mae = mean_absolute_error(GAM_explanations, LIME_explanations)\n",
    "    \n",
    "    #MSLE\n",
    "    msle = mean_squared_log_error(GAM_explanations, LIME_explanations)\n",
    "    \n",
    "    return rmse, mae, msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4c1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_features = ['covered_query_term_number_body','covered_query_term_number_anchor','covered_query_term_number_title',\n",
    "                 'covered_query_term_number_url','covered_query_term_number_whole_document','covered_query_term_ratio_body',\n",
    "                'covered_query_term_ratio_anchor','covered_query_term_ratio_title','covered_query_term_ratio_url',\n",
    "                 'covered_query_term_ratio_whole_document', 'stream_length_body', 'stream_length_anchor',\n",
    "                'stream_length_title','stream_length_url','stream_length_whole_document','sum_term_freq_body','sum_term_freq_anchor','sum_term_freq_title',\n",
    "                 'sum_term_freq_url','sum_term_freq_whole_document','min_term_freq_body','min_term_freq_anchor','min_term_freq_title',\n",
    "                 'min_term_freq_url','min_term_freq_whole_document','max_term_freq_body','max_term_freq_anchor','max_term_freq_title',\n",
    "                 'max_term_freq_url','max_term_freq_whole_document','mean_term_freq_body','mean_term_freq_anchor','mean_term_freq_title',\n",
    "                 'mean_term_freq_url','mean_term_freq_whole_document','sum_stream_length_normalized_term_freq_body','sum_stream_length_normalized_term_freq_anchor',\n",
    "                 'sum_stream_length_normalized_term_freq_title','sum_stream_length_normalized_term_freq_url','sum_stream_length_normalized_term_whole_document',\n",
    "                 'min_stream_length_normalized_term_freq_body','min_stream_length_normalized_term_freq_anchor','min_stream_length_normalized_term_freq_title',\n",
    "                 'min_stream_length_normalized_term_freq_url','min_stream_length_normalized_term_freq_whole_document','max_stream_length_normalized_term_freq_body',\n",
    "                 'max_stream_length_normalized_term_freq_anchor','max_stream_length_normalized_term_freq_title','max_stream_length_normalized_term_freq_url',\n",
    "                 'max_stream_length_normalized_term_freq_whole_document','mean_stream_length_normalized_term_freq_body','mean_stream_length_normalized_term_freq_anchor',\n",
    "                 'mean_stream_length_normalized_term_freq_title','mean_stream_length_normalized_term_freq_url','mean_stream_length_normalized_term_freq_whole_document','boolean_model_body',\n",
    "                 'boolean_model_anchor','boolean_model_title','boolean_model_url','boolean_model_whole_document','vector_space_model_body',\n",
    "                 'vector_space_model_anchor','vector_space_model_title','vector_space_model_url','vector_space_model_whole_document','BM25_body',\n",
    "                 'BM25_anchor','BM25_title','BM25_url','BM25_whole_document','LMIR.ABS_body','LMIR.ABS_anchor','LMIR.ABS_title','LMIR.ABS_url',\n",
    "                 'LMIR.ABS_whole_document','LMIR.DIR_body','LMIR.DIR_anchor','LMIR.DIR_title','LMIR.DIR_url','LMIR.DIR_whole_document','LMIR.JM_body',\n",
    "                 'LMIR.JM_anchor','LMIR.JM_title','LMIR.JM_url','LMIR.JM_whole_document','num_slash_url','length_url','inlink_number','outlink_number',\n",
    "                 'pagerank','siterank','qualityscore','qualityscore2','query_url_click_count','url_click_count','url_dwell_time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71263cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for explanations: 2.0460870265960693 \n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(96, 1), dtype=float32)\n",
      "RMSE: 0.38795579777322287\n",
      "MAE: 0.3627529723755689\n",
      "MSLE: 0.10214952239783125\n"
     ]
    }
   ],
   "source": [
    "grouped_qid = df_test.groupby('qid')\n",
    "group_data = grouped_qid.get_group(13)\n",
    "\n",
    "idx = 3\n",
    "\n",
    "lime = Explanations(df_test, name_features = name_features)\n",
    "GAM_explanations, LIME_explanations = lime.get_explanations(group_data, idx, \"gaussian\")\n",
    "\n",
    "print(LIME_explanations)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "normalized_explanations_GAM = minmax_scaler.fit_transform(GAM_explanations)\n",
    "normalized_explanations_LIME = minmax_scaler.fit_transform(LIME_explanations)\n",
    "\n",
    "rmse, mae, msle = calculating_metrics(normalized_explanations_GAM, normalized_explanations_LIME)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSLE:\", msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37bf4fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for explanations: 1.6276917457580566 \n",
      "Time took for explanations: 1.646200180053711 \n",
      "Time took for explanations: 1.6224274635314941 \n",
      "Time took for explanations: 1.634089469909668 \n",
      "Time took for explanations: 1.6872954368591309 \n",
      "Time took for explanations: 1.6048815250396729 \n",
      "Time took for explanations: 1.6185219287872314 \n",
      "Time took for explanations: 1.6734187602996826 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(group_data)):\n\u001b[1;32m     12\u001b[0m     lime \u001b[38;5;241m=\u001b[39m Explanations(df_test, name_features \u001b[38;5;241m=\u001b[39m name_features)\n\u001b[0;32m---> 13\u001b[0m     GAM_explanations, LIME_explanations \u001b[38;5;241m=\u001b[39m \u001b[43mlime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_explanations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mempirical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     minmax_scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     16\u001b[0m     normalized_explanations_GAM \u001b[38;5;241m=\u001b[39m minmax_scaler\u001b[38;5;241m.\u001b[39mfit_transform(GAM_explanations)\n",
      "Cell \u001b[0;32mIn[43], line 118\u001b[0m, in \u001b[0;36mExplanations.get_explanations\u001b[0;34m(self, qid_data, doc_idx, sampling)\u001b[0m\n\u001b[1;32m    115\u001b[0m ranked_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen_pred \u001b[38;5;129;01min\u001b[39;00m generated_predictions:\n\u001b[0;32m--> 118\u001b[0m     ranked_all\u001b[38;5;241m.\u001b[39mappend(rankdata([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m gen_pred])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m ranked_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ranked_all)\n\u001b[1;32m    121\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[43], line 118\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m ranked_all \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen_pred \u001b[38;5;129;01min\u001b[39;00m generated_predictions:\n\u001b[0;32m--> 118\u001b[0m     ranked_all\u001b[38;5;241m.\u001b[39mappend(rankdata([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m gen_pred])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m ranked_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ranked_all)\n\u001b[1;32m    121\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7374\u001b[0m, in \u001b[0;36m_TensorIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   7372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limit:\n\u001b[1;32m   7373\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m-> 7374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   7375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   7376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1170\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1170\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapi_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1172\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grouped_qid = df_test.groupby('qid')\n",
    "\n",
    "#Calculate 300 queries-doc, takes 10 minutes\n",
    "list_rmse = []\n",
    "list_mae = []\n",
    "list_msle = []\n",
    "\n",
    "for qid, group in grouped_qid:\n",
    "    \n",
    "    group_data = grouped_qid.get_group(qid)\n",
    "    for idx in range(0,len(group_data)):\n",
    "        \n",
    "        lime = Explanations(df_test, name_features = name_features)\n",
    "        GAM_explanations, LIME_explanations = lime.get_explanations(group_data, idx, \"empirical\")\n",
    "\n",
    "        minmax_scaler = MinMaxScaler()\n",
    "        normalized_explanations_GAM = minmax_scaler.fit_transform(GAM_explanations)\n",
    "        normalized_explanations_LIME = minmax_scaler.fit_transform(LIME_explanations)\n",
    "\n",
    "        rmse, mae, msle = calculating_metrics(normalized_explanations_GAM, normalized_explanations_LIME)\n",
    "        list_rmse.append(rmse)\n",
    "        list_mae.append(mae)\n",
    "        list_msle.append(msle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1024603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
