{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027a3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from scipy.stats import rankdata\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "from sklearn.linear_model import RidgeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8386bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compute_capability': (8, 6), 'device_name': 'NVIDIA GeForce RTX 3050 Laptop GPU'}\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    details = tf.config.experimental.get_device_details(gpu)\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94f2df",
   "metadata": {},
   "source": [
    "## Load test data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14de25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_yahoo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06c25a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance_label</th>\n",
       "      <th>qid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22939</td>\n",
       "      <td>0.30267</td>\n",
       "      <td>0.646710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34678</td>\n",
       "      <td>0.89603</td>\n",
       "      <td>0.122830</td>\n",
       "      <td>0.65796</td>\n",
       "      <td>0.77336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.47405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.178890</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054808</td>\n",
       "      <td>0.37080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22939</td>\n",
       "      <td>0.77818</td>\n",
       "      <td>0.099093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90748</td>\n",
       "      <td>0.35544</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.47580</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798600</td>\n",
       "      <td>0.39928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36453</td>\n",
       "      <td>0.635170</td>\n",
       "      <td>0.46792</td>\n",
       "      <td>0.76504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356410</td>\n",
       "      <td>0.85208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22939</td>\n",
       "      <td>0.77818</td>\n",
       "      <td>0.715050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97981</td>\n",
       "      <td>0.44943</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>0.71858</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>0.13551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64598</td>\n",
       "      <td>0.048097</td>\n",
       "      <td>0.46792</td>\n",
       "      <td>0.10065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.23288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22939</td>\n",
       "      <td>0.53862</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83239</td>\n",
       "      <td>0.29999</td>\n",
       "      <td>0.657750</td>\n",
       "      <td>0.41948</td>\n",
       "      <td>0.62482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570610</td>\n",
       "      <td>0.37363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36453</td>\n",
       "      <td>0.370790</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.27524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341860</td>\n",
       "      <td>0.54412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22939</td>\n",
       "      <td>0.59326</td>\n",
       "      <td>0.601570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77684</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.33855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.87514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155630</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   relevance_label    qid        1         2    3        4        5         6   \n",
       "0              0.0  22939  0.30267  0.646710  0.0  0.34678  0.89603  0.122830  \\\n",
       "1              1.0  22939  0.77818  0.099093  0.0  0.90748  0.35544  0.531800   \n",
       "2              1.0  22939  0.77818  0.715050  0.0  0.97981  0.44943  0.048097   \n",
       "3              0.0  22939  0.53862  0.279800  0.0  0.83239  0.29999  0.657750   \n",
       "4              0.0  22939  0.59326  0.601570  0.0  0.77684  0.00000  0.000000   \n",
       "\n",
       "         7        8  ...        91       92   93       94        95       96   \n",
       "0  0.65796  0.77336  ...  0.107100  0.47405  0.0  0.00000  0.178890  0.00000  \\\n",
       "1  0.47580  0.00000  ...  0.798600  0.39928  0.0  0.36453  0.635170  0.46792   \n",
       "2  0.71858  0.00000  ...  0.048097  0.13551  0.0  0.64598  0.048097  0.46792   \n",
       "3  0.41948  0.62482  ...  0.570610  0.37363  0.0  0.36453  0.370790  0.00000   \n",
       "4  0.00000  0.33855  ...  0.000000  0.00000  0.0  0.87514  0.000000  0.00000   \n",
       "\n",
       "        97   98        99      100  \n",
       "0  0.16873  0.0  0.054808  0.37080  \n",
       "1  0.76504  0.0  0.356410  0.85208  \n",
       "2  0.10065  0.0  0.104200  0.23288  \n",
       "3  0.27524  0.0  0.341860  0.54412  \n",
       "4  0.00000  0.0  0.155630  0.00000  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(\"yahoo_ranking_model_dir/export/latest_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_all(examples):\n",
    "    \n",
    "    exam = []\n",
    "    for idx, row in examples.iterrows():     \n",
    "\n",
    "        example_dict = {\n",
    "                       f'{feat_name}':_float_feature(feat_val) for \n",
    "                        feat_name, feat_val in zip(df_test.columns.tolist()[2:], row.iloc[2:].tolist())\n",
    "                    }    \n",
    "        \n",
    "        example_dict['relevance_label'] = _int64_feature(int(row['relevance_label']))\n",
    "\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=example_dict))\n",
    "        exam.append(example_proto.SerializeToString())\n",
    "    return exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d57bf9",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explanations:\n",
    "    def __init__(self, data, sample_size=20, visible_features=20):\n",
    "        self.data = data \n",
    "        self.sample_size = sample_size \n",
    "        self.kernel_width = np.sqrt(data.shape[1]) * .75\n",
    "        \n",
    "    def predict(self, instances): \n",
    "        tf_example_predictor = loaded_model.signatures[tf.saved_model.REGRESS_METHOD_NAME]\n",
    "        scores = tf_example_predictor(tf.convert_to_tensor(instances))[tf.saved_model.REGRESS_OUTPUTS]\n",
    "        return scores\n",
    "\n",
    "    def kernel(self, d):\n",
    "    #similarity or weight based on the Gaussian kernel function\n",
    "        return np.sqrt(np.exp(-(d ** 2) / self.kernel_width ** 2))\n",
    "    \n",
    "    def empirical_sampling(self, instance_explained):\n",
    "        generated_docs = []\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = instance_explained.shape[0]\n",
    "            total_feature_selected = np.random.randint(0, num_features - 2) \n",
    "            selected_features = np.random.randint(2, num_features, total_feature_selected)\n",
    "\n",
    "            for sel_feat in selected_features:\n",
    "                instance_explained[sel_feat] = np.random.choice(self.data.iloc[:, sel_feat], 1)[0]\n",
    "\n",
    "            generated_docs.append(instance_explained)\n",
    "\n",
    "        return generated_docs\n",
    "    \n",
    "    def lime_inverse_zscore(self, instance_explained):\n",
    "        generated_docs = []\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = instance_explained.shape[0] \n",
    "            total_feature_selected = np.random.randint(0, num_features - 2)\n",
    "            selected_features = np.random.randint(2, num_features, total_feature_selected)\n",
    "\n",
    "            for sel_feat in selected_features:\n",
    "                mu = np.mean(self.data.iloc[:, sel_feat].values)\n",
    "                sigma = np.std(self.data.iloc[:, sel_feat].values)\n",
    "                z = np.random.normal(0, 1)\n",
    "                instance_explained[sel_feat] = z * sigma + mu\n",
    "\n",
    "            generated_docs.append(instance_explained)\n",
    "\n",
    "        return generated_docs\n",
    "    \n",
    "    def gaussian_sampling(self, instance_explained):\n",
    "        generated_docs = []\n",
    "        \n",
    "        unique_vals = {}\n",
    "        exclude_features = []\n",
    "\n",
    "        for i in range(2, self.data.shape[1]):\n",
    "            dist = np.abs(self.data.iloc[:, i] - instance_explained[i])\n",
    "            unique_val = dist[ dist < np.std(self.data.iloc[:, i])].unique()\n",
    "            \n",
    "            if len(unique_val) > 0: \n",
    "                unique_vals[i] = unique_val\n",
    "            else: \n",
    "                exclude_features.append(i)\n",
    "\n",
    "        for t in range(0, self.sample_size):\n",
    "            instance_explained = copy.copy(instance_explained)\n",
    "            num_features = instance_explained.shape[0] \n",
    "            total_feature_selected = np.random.randint(0, num_features - 2 - len(exclude_features))\n",
    "            available_features = np.setxor1d(np.arange(2, num_features), exclude_features)\n",
    "            selected_features = np.random.choice(available_features, total_feature_selected)\n",
    "            \n",
    "            for c_feat in selected_features:\n",
    "                instance_explained[c_feat] = np.random.choice(unique_vals[c_feat], 1)[0]\n",
    "\n",
    "            generated_docs.append(instance_explained)\n",
    "\n",
    "        return generated_docs\n",
    "        \n",
    "    def get_exp(self, qid_data, doc_idx, sampling): \n",
    "        #qid is a pandas dataframe\n",
    "        #doc_idx index instance to explain\n",
    "        start = time.time()\n",
    "\n",
    "        docs = serialize_all(qid_data) #list of tensor examples\n",
    "\n",
    "        original_scores = self.predict(docs) #prediction of docs given query\n",
    "        base_rank = rankdata([-1 * i for i in original_scores]).astype(int) - 1\n",
    "\n",
    "        instance_explained = copy.copy(qid_data.iloc[doc_idx])\n",
    "        \n",
    "        #returns list of new documents samples\n",
    "        if sampling == 'empirical':\n",
    "            generated_docs = self.empirical_sampling(instance_explained)\n",
    "        elif sampling == 'gaussian':\n",
    "            generated_docs = self.gaussian_sampling(instance_explained)\n",
    "        elif sampling == 'lime':\n",
    "            generated_docs = self.lime_inverse_zscore(instance_explained)\n",
    "        \n",
    "        generated_predictions = []\n",
    "\n",
    "        #for each sample\n",
    "        for t in range(0, self.sample_size):\n",
    "            temp_docs = copy.copy(docs) #copy tensors\n",
    "            temp_docs[doc_idx] = serialize_all(generated_docs[t].to_frame().T)[0] #the selected instance is replaced\n",
    "            genere_pred = self.predict(temp_docs)\n",
    "            generated_predictions.append(genere_pred) #return tensor predict\n",
    "\n",
    "        #base_rank = rankdata([-1 * i for i in original_scores.flatten()]).astype(int) - 1\n",
    "        \n",
    "        ranked_all = []\n",
    "        \n",
    "        for gen_pred in generated_predictions:\n",
    "            ranked_all.append(rankdata([-1 * i for i in gen_pred]).astype(int) - 1)\n",
    "        ranked_all = np.array(ranked_all)\n",
    "        \n",
    "        labels = []\n",
    "        #binary labels\n",
    "        for ranked in ranked_all: \n",
    "            if ranked[doc_idx] <= base_rank[doc_idx]: \n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "                \n",
    "        gen_docs = []\n",
    "        \n",
    "        for i in range(0, self.sample_size):\n",
    "            gen_docs.append(generated_docs[i].values[2:]) #all features of generated_docs\n",
    "        gen_docs = np.array(gen_docs).astype(np.float32)\n",
    "        \n",
    "        i_explained = instance_explained.values[2:].astype(np.float32)\n",
    "        distances = np.linalg.norm(gen_docs - i_explained, axis=1) #euclidean distance\n",
    "        k_weights = self.kernel(distances).astype(np.float32)\n",
    "        \n",
    "        clf = RidgeClassifier().fit(gen_docs, labels, sample_weight=k_weights)\n",
    "        end = time.time()\n",
    "        \n",
    "        print('Time took for explanations: {} '.format(end - start))\n",
    "        \n",
    "        return original_scores, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_qid = df_test.groupby('qid')\n",
    "group_data = grouped_qid.get_group(23834)\n",
    "\n",
    "idx = 32\n",
    "\n",
    "lime = Explanations(df_test)\n",
    "GAM_scores, LIME_model = lime.get_exp(group_data, idx, \"empirical\")\n",
    "\n",
    "base_rank = rankdata([-1 * i for i in GAM_scores]).astype(int) - 1\n",
    "\n",
    "sorted_lists = sorted(zip(base_rank, group_data['relevance_label'].tolist()))\n",
    "sorted_second_list = [item[1] for item in sorted_lists]\n",
    "\n",
    "print(sorted_second_list)\n",
    "\n",
    "print(LIME_model.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
